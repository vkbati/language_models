{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe718c3-96a0-4bf0-ba86-5cf622773265",
   "metadata": {},
   "source": [
    "# Hate speech classification task\n",
    "\n",
    "## Veysel Kaan Bati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487a4f0-b112-4887-bd83-af1ef4c60497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbee63a6-08b7-40b1-a7d0-5b7778b80f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_data = ('/compLing/students/courses/deepLearning/assignment02/labeled_data.csv')\n",
    "data = pd.read_csv(url_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "194be515-a3ce-482d-95f7-7bf60f08076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[[\"class\", \"tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96ffa8af-66dc-4480-acfd-029a037f60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)\n",
    "    # Remove special characters and punctuation\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "    tweet = re.sub(r'amp', '', tweet)\n",
    "    tweet = re.sub(r'rt', '', tweet)\n",
    "    tweet = re.sub(' +', ' ', tweet)\n",
    "    tweet = tweet.replace('\\n', '')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f7b7b9c-7471-45c8-8d77-8c2a1e6f6cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49351/946608730.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['tweet'] = filtered_data['tweet'].apply(lambda x: preprocess_tweet(x))\n"
     ]
    }
   ],
   "source": [
    "filtered_data['tweet'] = filtered_data['tweet'].apply(lambda x: preprocess_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfd9c52d-0c04-4f9c-8bd5-19ab0b048567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>as a woman you shouldnt complain about cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>boy dats coldtyga dwn bad for cuffin dat hoe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dawg you ever fuck a bitch and she sta to cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>the shit you hear about me might be true or i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      2   as a woman you shouldnt complain about cleani...\n",
       "1      1   boy dats coldtyga dwn bad for cuffin dat hoe ...\n",
       "2      1   dawg you ever fuck a bitch and she sta to cry...\n",
       "3      1                             she look like a tranny\n",
       "4      1   the shit you hear about me might be true or i..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689a6ce4-08a3-4c44-a1e0-e5b10830f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (19826, 2)\n",
      "Validation set shape: (2478, 2)\n",
      "Test set shape: (2479, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(filtered_data, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting DataFrames\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15604f09-7f50-4100-9a59-b2c828421e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15272</th>\n",
       "      <td>0</td>\n",
       "      <td>well how else will white ppl get us to forget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9351</th>\n",
       "      <td>2</td>\n",
       "      <td>funny thing isits not just the people doing it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20323</th>\n",
       "      <td>1</td>\n",
       "      <td>nigga messed with the wrong bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch ass nigggaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>1</td>\n",
       "      <td>so that real bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "15272      0   well how else will white ppl get us to forget...\n",
       "9351       2  funny thing isits not just the people doing it...\n",
       "20323      1                 nigga messed with the wrong bitch \n",
       "3638       1                                 bitch ass nigggaaa\n",
       "20579      1                                 so that real bitch"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14ecffb8-2410-49e3-bea4-d8c3e687e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43953f-ca01-4c28-a5d0-7688df7fa6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_words,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782c46b7-2592-45b7-9aab-94f9a65da952",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization.adapt(train_df[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c20112c0-5b13-46fa-9a72-b31b71cd0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_vec = text_vectorization(train_df[\"tweet\"])\n",
    "t_val_vec = text_vectorization(val_df[\"tweet\"])\n",
    "t_test_vec = text_vectorization(test_df[\"tweet\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614bf109-44cc-4dff-9e5e-630e9df524b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  72    2  352    6 1158 1197   59 3580   30   29  296   72    2   89\n",
      "    6  192  167  146    5   53   55    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int64)\n",
      "as a woman you shouldnt complain about cleaning up your house as a man you should always take the trash out                             \n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "test_sentence = filtered_data[\"tweet\"][0]\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)\n",
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f3f54f-7844-4b70-99de-111ab4a8993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'a', 'bitch', 'i', 'the', 'you', 'to', 'and', 'my']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f95438dc-5fde-4a63-888f-a2d66630444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_path = '/compLing/students/courses/deepLearning/assignment02/glove.twitter.27B.100d.txt'\n",
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "with open(glove_path) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca1d4d24-9517-463a-b139-816547773e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "num_words = min(max_words, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b3769a-df3c-4ae6-bd35-b0b0ee33174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=(max_len,))\n",
    "tok = keras.layers.Embedding(input_dim=text_vectorization.vocabulary_size(),\n",
    "                           output_dim=embedding_dim,\n",
    "                           weights=[embedding_matrix],\n",
    "                           trainable=False)(input_layer)\n",
    "\n",
    "position_embeddings = keras_nlp.layers.PositionEmbedding(\n",
    "    sequence_length=max_len)(tok)\n",
    "x = tok + position_embeddings\n",
    "\n",
    "x = keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4)(x)\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = keras.layers.Dense(3, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c22d6bd4-91c8-4a0d-bb81-ff405b4b9317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d2e878-a9ca-4e31-9b2f-95ff78fc17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam()  # You can also use 'rmsprop' if preferred\n",
    "model.compile(optimizer=optimizer, loss=SparseCategoricalCrossentropy(), metrics=[SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a0174e2-4ab7-4c01-9708-5daae24db42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"hate_detect.tf\",\n",
    "                                    save_best_only=True)\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc905ff9-15dc-43a6-b730-8886a7c5d0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3621 - sparse_categorical_accuracy: 0.8770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as self_attention_layer_layer_call_fn, self_attention_layer_layer_call_and_return_conditional_losses, self_attention_layer_norm_layer_call_fn, self_attention_layer_norm_layer_call_and_return_conditional_losses, self_attention_dropout_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 13s 38ms/step - loss: 0.3620 - sparse_categorical_accuracy: 0.8768 - val_loss: 0.2956 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 2/10\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2773 - sparse_categorical_accuracy: 0.9036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as self_attention_layer_layer_call_fn, self_attention_layer_layer_call_and_return_conditional_losses, self_attention_layer_norm_layer_call_fn, self_attention_layer_norm_layer_call_and_return_conditional_losses, self_attention_dropout_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 12s 37ms/step - loss: 0.2774 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.2885 - val_sparse_categorical_accuracy: 0.8959\n",
      "Epoch 3/10\n",
      "310/310 [==============================] - 10s 32ms/step - loss: 0.2679 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.3069 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 4/10\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2583 - sparse_categorical_accuracy: 0.9077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as self_attention_layer_layer_call_fn, self_attention_layer_layer_call_and_return_conditional_losses, self_attention_layer_norm_layer_call_fn, self_attention_layer_norm_layer_call_and_return_conditional_losses, self_attention_dropout_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 11s 36ms/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.2814 - val_sparse_categorical_accuracy: 0.8935\n",
      "Epoch 5/10\n",
      "310/310 [==============================] - 10s 31ms/step - loss: 0.2535 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.2839 - val_sparse_categorical_accuracy: 0.8947\n",
      "Epoch 6/10\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2477 - sparse_categorical_accuracy: 0.9106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as self_attention_layer_layer_call_fn, self_attention_layer_layer_call_and_return_conditional_losses, self_attention_layer_norm_layer_call_fn, self_attention_layer_norm_layer_call_and_return_conditional_losses, self_attention_dropout_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_detect.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 11s 36ms/step - loss: 0.2474 - sparse_categorical_accuracy: 0.9108 - val_loss: 0.2752 - val_sparse_categorical_accuracy: 0.9048\n",
      "Epoch 7/10\n",
      "310/310 [==============================] - 10s 32ms/step - loss: 0.2443 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.2900 - val_sparse_categorical_accuracy: 0.8999\n",
      "Epoch 8/10\n",
      "310/310 [==============================] - 10s 31ms/step - loss: 0.2384 - sparse_categorical_accuracy: 0.9130 - val_loss: 0.2821 - val_sparse_categorical_accuracy: 0.8995\n",
      "Epoch 9/10\n",
      "310/310 [==============================] - 10s 32ms/step - loss: 0.2353 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.2784 - val_sparse_categorical_accuracy: 0.9052\n",
      "Epoch 10/10\n",
      "310/310 [==============================] - 10s 32ms/step - loss: 0.2314 - sparse_categorical_accuracy: 0.9172 - val_loss: 0.2795 - val_sparse_categorical_accuracy: 0.9003\n"
     ]
    }
   ],
   "source": [
    "model.fit(t_train_vec, train_df[\"class\"], epochs=10, batch_size=64, validation_data=(t_val_vec, val_df[\"class\"]), callbacks=callbacks)\n",
    "\n",
    "model =  keras.models.load_model(\"hate_detect.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ada3524e-47c2-4031-92cb-6c0d5ba8e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.10      0.16       133\n",
      "           1       0.93      0.95      0.94      1924\n",
      "           2       0.80      0.90      0.85       422\n",
      "\n",
      "    accuracy                           0.90      2479\n",
      "   macro avg       0.73      0.65      0.65      2479\n",
      "weighted avg       0.88      0.90      0.88      2479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(t_test_vec) # x_test here should be your test data\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(test_df[\"class\"], y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dfcbc7f-5e8a-4468-a9b9-d99f2d2e6a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24783"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(filtered_data)\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b88bc8d-5822-4dc3-8b70-eea8949f163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.480369608199169"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_words_per_sample = filtered_data['tweet'].apply(lambda x: len(x.split())).mean()\n",
    "avg_words_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eafdfb3-5833-45b0-998e-06025c004484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985.7584973860414"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples / avg_words_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf8d309c-07aa-4a51-a670-ef5576cd9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer with bigrams\n",
    "tf_vectorizer = keras.layers.TextVectorization(\n",
    "    max_tokens=max_words,\n",
    "    output_mode=\"tf_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae5ec5a6-146c-449f-ad00-1dd8d7dc6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer.adapt(train_df[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "963ed66e-a547-4ffd-937a-57ca0fb605f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_vec = tf_vectorizer(train_df[\"tweet\"])\n",
    "tf_val_vec = tf_vectorizer(val_df[\"tweet\"])\n",
    "tf_test_vec = tf_vectorizer(test_df[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fca558a-1cfc-42a8-b00b-67913794b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = Sequential()\n",
    "model_tf.add(Dense(128, activation='relu', input_shape=(tf_train_vec.shape[1],)))\n",
    "model_tf.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3ea0d45-b977-4bc1-82d7-1628f8a6b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.3907 - sparse_categorical_accuracy: 0.8688 - val_loss: 0.3441 - val_sparse_categorical_accuracy: 0.8846\n",
      "Epoch 2/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.4102 - val_sparse_categorical_accuracy: 0.8785\n",
      "Epoch 3/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.0597 - sparse_categorical_accuracy: 0.9808 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.8753\n",
      "Epoch 4/10\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.5339 - val_sparse_categorical_accuracy: 0.8717\n",
      "Epoch 5/10\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.8733\n",
      "Epoch 6/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.8725\n",
      "Epoch 7/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.8773\n",
      "Epoch 8/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.7272 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 9/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.7735 - val_sparse_categorical_accuracy: 0.8745\n",
      "Epoch 10/10\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.7892 - val_sparse_categorical_accuracy: 0.8701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd585c76ce0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "model_tf.fit(tf_train_vec, train_df[\"class\"] , epochs=10, batch_size=64, validation_data=(tf_val_vec, val_df[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45c404d5-6ced-4dfa-aa02-e79680872139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 903us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.19      0.23       133\n",
      "           1       0.90      0.95      0.92      1924\n",
      "           2       0.82      0.73      0.77       422\n",
      "\n",
      "    accuracy                           0.87      2479\n",
      "   macro avg       0.68      0.62      0.64      2479\n",
      "weighted avg       0.86      0.87      0.86      2479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_tf.predict(tf_test_vec) \n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(test_df[\"class\"], y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c675e7-b89d-4d35-95bd-f3e598dcc1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
