{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30636,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "# Machine translation task with transformer archtitecture."
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget  http://www.manythings.org/anki/por-eng.zip\n",
    "!unzip -q /kaggle/working/por-eng.zip\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T09:27:34.460834Z",
     "iopub.execute_input": "2024-01-26T09:27:34.461230Z",
     "iopub.status.idle": "2024-01-26T09:27:49.235714Z",
     "shell.execute_reply.started": "2024-01-26T09:27:34.461193Z",
     "shell.execute_reply": "2024-01-26T09:27:49.234753Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Using TensorFlow backend\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T09:27:51.244238Z",
     "iopub.execute_input": "2024-01-26T09:27:51.245388Z",
     "iopub.status.idle": "2024-01-26T09:27:51.421825Z",
     "shell.execute_reply.started": "2024-01-26T09:27:51.245341Z",
     "shell.execute_reply": "2024-01-26T09:27:51.420835Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "1 Physical GPUs, 1 Logical GPUs\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_file = \"/kaggle/working/por.txt\"\n",
    "\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "text_pairs = []\n",
    "\n",
    "for line in lines:\n",
    "    # Split the line into fields using tabs\n",
    "    fields = line.split(\"\\t\")\n",
    "    \n",
    "    # Keep only the first two fields\n",
    "    english, portuguese = fields[:2]\n",
    "\n",
    "    # Modify the 'portuguese' value\n",
    "    portuguese = \"[start] \" + portuguese + \" [end]\"\n",
    "\n",
    "    # Append the modified pair to text_pairs\n",
    "    text_pairs.append((english, portuguese))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T09:29:51.496264Z",
     "iopub.execute_input": "2024-01-26T09:29:51.497187Z",
     "iopub.status.idle": "2024-01-26T09:29:51.916308Z",
     "shell.execute_reply.started": "2024-01-26T09:29:51.497151Z",
     "shell.execute_reply": "2024-01-26T09:29:51.915494Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(random.choice(text_pairs))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T09:30:03.303532Z",
     "iopub.execute_input": "2024-01-26T09:30:03.304237Z",
     "iopub.status.idle": "2024-01-26T09:30:03.308863Z",
     "shell.execute_reply.started": "2024-01-26T09:30:03.304207Z",
     "shell.execute_reply": "2024-01-26T09:30:03.307992Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "('The alarm went off.', '[start] O alarme disparou. [end]')\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T09:30:18.182278Z",
     "iopub.execute_input": "2024-01-26T09:30:18.183135Z",
     "iopub.status.idle": "2024-01-26T09:30:18.361652Z",
     "shell.execute_reply.started": "2024-01-26T09:30:18.183099Z",
     "shell.execute_reply": "2024-01-26T09:30:18.360813Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# [ and ] cannot be in the list of excluded characters!\n",
    "punct_to_exclude = '!\"#$%&()*+-/:;<=>@\\\\^_`{|}~'\n",
    "punct_to_tokenize = '.,:;!¡?¿'\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    stripped = tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(punct_to_exclude)}]\", \"\")\n",
    "    stripped = tf.strings.regex_replace(\n",
    "        stripped, f\"([{re.escape(punct_to_tokenize)}])\", r\" \\1\")\n",
    "    return stripped\n",
    "\n",
    "vocab_size = 15000            # looking only at the most frequent 15,000 words\n",
    "sequence_length = 45\n",
    "\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=custom_standardization\n",
    ")\n",
    "\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization\n",
    ")\n",
    "\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:18:15.206958Z",
     "iopub.execute_input": "2024-01-26T10:18:15.207350Z",
     "iopub.status.idle": "2024-01-26T10:18:34.344213Z",
     "shell.execute_reply.started": "2024-01-26T10:18:15.207319Z",
     "shell.execute_reply": "2024-01-26T10:18:34.343393Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "source_vectorization.get_vocabulary()[:10]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:18:37.531128Z",
     "iopub.execute_input": "2024-01-26T10:18:37.531523Z",
     "iopub.status.idle": "2024-01-26T10:18:37.570490Z",
     "shell.execute_reply.started": "2024-01-26T10:18:37.531492Z",
     "shell.execute_reply": "2024-01-26T10:18:37.569438Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "execution_count": 22,
     "output_type": "execute_result",
     "data": {
      "text/plain": "['', '[UNK]', '.', 'tom', 'i', 'to', 'you', 'the', '?', 'a']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 256\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\"english\": eng,\n",
    "             \"spanish\": spa[:, :-1]\n",
    "            }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.shuffle(2048).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:18:57.641270Z",
     "iopub.execute_input": "2024-01-26T10:18:57.641913Z",
     "iopub.status.idle": "2024-01-26T10:18:59.442977Z",
     "shell.execute_reply.started": "2024-01-26T10:18:57.641863Z",
     "shell.execute_reply": "2024-01-26T10:18:59.442162Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eng_texts, spa_texts = zip(*text_pairs)\n",
    "eng_texts = list(eng_texts)\n",
    "spa_texts = list(spa_texts)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:18:59.445172Z",
     "iopub.execute_input": "2024-01-26T10:18:59.445621Z",
     "iopub.status.idle": "2024-01-26T10:18:59.864298Z",
     "shell.execute_reply.started": "2024-01-26T10:18:59.445586Z",
     "shell.execute_reply": "2024-01-26T10:18:59.863510Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:18:59.865472Z",
     "iopub.execute_input": "2024-01-26T10:18:59.865858Z",
     "iopub.status.idle": "2024-01-26T10:19:00.300825Z",
     "shell.execute_reply.started": "2024-01-26T10:18:59.865786Z",
     "shell.execute_reply": "2024-01-26T10:19:00.299832Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "inputs['english'].shape: (256, 45)\ninputs['spanish'].shape: (256, 45)\ntargets.shape: (256, 45)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "embed_dim = 512\n",
    "dense_dim = 2048\n",
    "num_heads = 16\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:08.686950Z",
     "iopub.execute_input": "2024-01-26T10:19:08.687888Z",
     "iopub.status.idle": "2024-01-26T10:19:08.692061Z",
     "shell.execute_reply.started": "2024-01-26T10:19:08.687851Z",
     "shell.execute_reply": "2024-01-26T10:19:08.690939Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_inputs = keras.layers.Input(shape=(None,), dtype=\"int64\", name=\"english\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:09.832260Z",
     "iopub.execute_input": "2024-01-26T10:19:09.832615Z",
     "iopub.status.idle": "2024-01-26T10:19:09.838889Z",
     "shell.execute_reply.started": "2024-01-26T10:19:09.832589Z",
     "shell.execute_reply": "2024-01-26T10:19:09.837970Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "token_embeddings = keras.layers.Embedding(\n",
    "        input_dim=vocab_size, output_dim=embed_dim\n",
    "    )(encoder_inputs)\n",
    "position_embeddings = keras_nlp.layers.PositionEmbedding(\n",
    "    sequence_length=sequence_length)(token_embeddings)\n",
    "x = token_embeddings + position_embeddings\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:10.758546Z",
     "iopub.execute_input": "2024-01-26T10:19:10.759311Z",
     "iopub.status.idle": "2024-01-26T10:19:10.810955Z",
     "shell.execute_reply.started": "2024-01-26T10:19:10.759279Z",
     "shell.execute_reply": "2024-01-26T10:19:10.810005Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_outputs = keras_nlp.layers.TransformerEncoder(\n",
    "    intermediate_dim=dense_dim, num_heads=num_heads)(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:11.654839Z",
     "iopub.execute_input": "2024-01-26T10:19:11.655449Z",
     "iopub.status.idle": "2024-01-26T10:19:11.769954Z",
     "shell.execute_reply.started": "2024-01-26T10:19:11.655417Z",
     "shell.execute_reply": "2024-01-26T10:19:11.769115Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "token_embeddings = keras.layers.Embedding(\n",
    "        input_dim=vocab_size, output_dim=embed_dim\n",
    "    )(decoder_inputs)\n",
    "position_embeddings = keras_nlp.layers.PositionEmbedding(\n",
    "    sequence_length=sequence_length)(token_embeddings)\n",
    "x = token_embeddings + position_embeddings"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:12.463286Z",
     "iopub.execute_input": "2024-01-26T10:19:12.463667Z",
     "iopub.status.idle": "2024-01-26T10:19:12.500769Z",
     "shell.execute_reply.started": "2024-01-26T10:19:12.463637Z",
     "shell.execute_reply": "2024-01-26T10:19:12.500009Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = keras_nlp.layers.TransformerDecoder(\n",
    "    intermediate_dim=dense_dim, num_heads=num_heads)(x, encoder_outputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs = keras.layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:13.550034Z",
     "iopub.execute_input": "2024-01-26T10:19:13.550885Z",
     "iopub.status.idle": "2024-01-26T10:19:13.872212Z",
     "shell.execute_reply.started": "2024-01-26T10:19:13.550848Z",
     "shell.execute_reply": "2024-01-26T10:19:13.871148Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T10:19:14.763457Z",
     "iopub.execute_input": "2024-01-26T10:19:14.764309Z",
     "iopub.status.idle": "2024-01-26T11:27:18.243724Z",
     "shell.execute_reply.started": "2024-01-26T10:19:14.764278Z",
     "shell.execute_reply": "2024-01-26T11:27:18.242763Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/30\n524/524 [==============================] - 162s 290ms/step - loss: 0.8524 - accuracy: 0.8703 - val_loss: 0.6276 - val_accuracy: 0.8854\nEpoch 2/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.6144 - accuracy: 0.8870 - val_loss: 0.5743 - val_accuracy: 0.8908\nEpoch 3/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.5134 - accuracy: 0.9017 - val_loss: 0.4326 - val_accuracy: 0.9157\nEpoch 4/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.3471 - accuracy: 0.9294 - val_loss: 0.2993 - val_accuracy: 0.9390\nEpoch 5/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.2472 - accuracy: 0.9461 - val_loss: 0.2463 - val_accuracy: 0.9484\nEpoch 6/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1970 - accuracy: 0.9547 - val_loss: 0.2220 - val_accuracy: 0.9531\nEpoch 7/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1676 - accuracy: 0.9597 - val_loss: 0.2097 - val_accuracy: 0.9552\nEpoch 8/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1476 - accuracy: 0.9633 - val_loss: 0.2025 - val_accuracy: 0.9568\nEpoch 9/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1329 - accuracy: 0.9660 - val_loss: 0.2002 - val_accuracy: 0.9577\nEpoch 10/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1211 - accuracy: 0.9682 - val_loss: 0.1985 - val_accuracy: 0.9587\nEpoch 11/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1119 - accuracy: 0.9700 - val_loss: 0.2005 - val_accuracy: 0.9587\nEpoch 12/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.1043 - accuracy: 0.9716 - val_loss: 0.2020 - val_accuracy: 0.9595\nEpoch 13/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0976 - accuracy: 0.9729 - val_loss: 0.2032 - val_accuracy: 0.9596\nEpoch 14/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0919 - accuracy: 0.9740 - val_loss: 0.2070 - val_accuracy: 0.9594\nEpoch 15/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0863 - accuracy: 0.9753 - val_loss: 0.2077 - val_accuracy: 0.9596\nEpoch 16/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0822 - accuracy: 0.9762 - val_loss: 0.2123 - val_accuracy: 0.9593\nEpoch 17/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0787 - accuracy: 0.9770 - val_loss: 0.2161 - val_accuracy: 0.9601\nEpoch 18/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0753 - accuracy: 0.9777 - val_loss: 0.2189 - val_accuracy: 0.9599\nEpoch 19/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0724 - accuracy: 0.9784 - val_loss: 0.2227 - val_accuracy: 0.9602\nEpoch 20/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0697 - accuracy: 0.9791 - val_loss: 0.2263 - val_accuracy: 0.9597\nEpoch 21/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0670 - accuracy: 0.9798 - val_loss: 0.2316 - val_accuracy: 0.9599\nEpoch 22/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.2340 - val_accuracy: 0.9598\nEpoch 23/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 0.2297 - val_accuracy: 0.9603\nEpoch 24/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.2301 - val_accuracy: 0.9605\nEpoch 25/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0590 - accuracy: 0.9817 - val_loss: 0.2345 - val_accuracy: 0.9601\nEpoch 26/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0571 - accuracy: 0.9822 - val_loss: 0.2371 - val_accuracy: 0.9598\nEpoch 27/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.2417 - val_accuracy: 0.9597\nEpoch 28/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0542 - accuracy: 0.9830 - val_loss: 0.2401 - val_accuracy: 0.9606\nEpoch 29/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0525 - accuracy: 0.9834 - val_loss: 0.2417 - val_accuracy: 0.9608\nEpoch 30/30\n524/524 [==============================] - 135s 258ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.2454 - val_accuracy: 0.9605\n",
     "output_type": "stream"
    },
    {
     "execution_count": 32,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7eb6637d1ea0>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "por_vocab = target_vectorization.get_vocabulary()\n",
    "por_index_lookup = dict(zip(range(len(por_vocab)), por_vocab))\n",
    "max_decoded_sentence_length = 45\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = por_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_por_texts = [pair[1] for pair in test_pairs]\n",
    "test_texts = list(zip(test_eng_texts, test_por_texts))\n",
    "for _ in range(20):\n",
    "    input_sentence, target_sentence = random.choice(test_texts)\n",
    "    print(\"-\")\n",
    "    print(\"Input: \", input_sentence)\n",
    "    print(\"Reference: \", target_sentence)\n",
    "    print(\"Prediction: \", decode_sequence(input_sentence))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T11:29:29.755294Z",
     "iopub.execute_input": "2024-01-26T11:29:29.755724Z",
     "iopub.status.idle": "2024-01-26T11:29:37.505796Z",
     "shell.execute_reply.started": "2024-01-26T11:29:29.755691Z",
     "shell.execute_reply": "2024-01-26T11:29:37.504826Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": "-\nInput:  Tom dropped Mary off at the library.\nReference:  [start] Tom deixou Mary na biblioteca. [end]\nPrediction:  [start] tom deixou mary na biblioteca . [end]\n-\nInput:  I know the reason that she quit her job.\nReference:  [start] Eu sei o porquê dela ter largado o emprego. [end]\nPrediction:  [start] eu sei que ela tem razão para deixar o trabalho deles . [end]\n-\nInput:  Tom never mentioned your name.\nReference:  [start] Tom nunca mencionou o seu nome. [end]\nPrediction:  [start] tom nunca mencionou o nome deles . [end]\n-\nInput:  Have you really lost your wallet again?\nReference:  [start] Você já perdeu sua carteira de novo? [end]\nPrediction:  [start] você realmente perdeu sua carteira de novo ? [end]\n-\nInput:  I wish I had something to drink.\nReference:  [start] Eu queria ter algo para beber. [end]\nPrediction:  [start] queria ter uma coisa para beber . [end]\n-\nInput:  There's no more salt.\nReference:  [start] Não tem mais sal. [end]\nPrediction:  [start] não tem mais sal . [end]\n-\nInput:  There were few people on the beach.\nReference:  [start] Havia poucas pessoas na praia. [end]\nPrediction:  [start] havia várias pessoas na praia . [end]\n-\nInput:  Tom's correct.\nReference:  [start] Tom tem razão. [end]\nPrediction:  [start] tom está certo . [end]\n-\nInput:  What does it say?\nReference:  [start] O que isso quer dizer? [end]\nPrediction:  [start] o que isso diz ? [end]\n-\nInput:  I know Tom loves living here.\nReference:  [start] Sei que o Tom ama morar aqui. [end]\nPrediction:  [start] eu sei que o tom ama morar aqui . [end]\n-\nInput:  I have no talent.\nReference:  [start] Não tenho talento. [end]\nPrediction:  [start] eu não tenho talento . [end]\n-\nInput:  Is it true that men have oilier skin than women?\nReference:  [start] É verdade que os homens têm a pele mais oleosa do que as mulheres? [end]\nPrediction:  [start] É verdade que os homens têm [UNK] mais as coisas do que sabem ? [end]\n-\nInput:  You're not going to want to miss this.\nReference:  [start] Você não vai querer perder isto. [end]\nPrediction:  [start] você não vai querer perder isso . [end]\n-\nInput:  I want to raise a family.\nReference:  [start] Quero formar uma família. [end]\nPrediction:  [start] eu quero passar uma família . [end]\n-\nInput:  I thought you said that you were alone.\nReference:  [start] Eu pensei que você tinha dito que estava sozinha. [end]\nPrediction:  [start] achei que você disse que estava sozinho . [end]\n-\nInput:  They insist that he should go.\nReference:  [start] Eles insistem que ele deveria ir. [end]\nPrediction:  [start] eles tentaram fazer isso . [end]\n-\nInput:  The door was wide open.\nReference:  [start] A porta estava escancarada. [end]\nPrediction:  [start] a porta estava bem aberta . [end]\n-\nInput:  Please give me a minute to explain.\nReference:  [start] Por favor me dê um minuto para explicar. [end]\nPrediction:  [start] por favor , me dê um minuto . [end]\n-\nInput:  I hope that doesn't ever happen.\nReference:  [start] Espero que isso nunca aconteça. [end]\nPrediction:  [start] espero que isso nunca acontece . [end]\n-\nInput:  It's been raining heavily since this morning, so I don't want to go anywhere.\nReference:  [start] Está chovendo forte desde esta manhã, então não quero ir a lugar algum. [end]\nPrediction:  [start] está chovendo muito cedo hoje de manhã , então eu não quero . [end]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Example machine-generated translations\n",
    "hypotheses = [\"está chovendo muito cedo hoje de manhã , então eu não quero\"]\n",
    "# Example reference translations\n",
    "references = [[\"Está chovendo forte desde esta manhã, então não quero ir a lugar algum\", \"Está a chover muito desde esta manhã, por isso não quero ir a lado nenhum\"]]\n",
    "\n",
    "# Tokenize the translations\n",
    "hypotheses = [nltk.word_tokenize(sent) for sent in hypotheses]\n",
    "references = [[nltk.word_tokenize(sent) for sent in ref] for ref in references]\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu(references, hypotheses)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score * 100:.2f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T11:36:31.719665Z",
     "iopub.execute_input": "2024-01-26T11:36:31.720427Z",
     "iopub.status.idle": "2024-01-26T11:36:32.509159Z",
     "shell.execute_reply.started": "2024-01-26T11:36:31.720390Z",
     "shell.execute_reply": "2024-01-26T11:36:32.508221Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "BLEU Score: 30.06\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "transformer.save(\"veysel_kaan_bati.mtl.keras\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-26T11:42:31.067057Z",
     "iopub.execute_input": "2024-01-26T11:42:31.067460Z",
     "iopub.status.idle": "2024-01-26T11:42:32.213457Z",
     "shell.execute_reply.started": "2024-01-26T11:42:31.067429Z",
     "shell.execute_reply": "2024-01-26T11:42:32.211975Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
